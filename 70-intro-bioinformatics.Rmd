# Bioinformatics {#sec:bioinfo}

As already alluded to earlier, [Wikipedia
defines](https://en.wikipedia.org/wiki/Bioinformatics) bioinformatics
as

> Bioinformatics is an interdisciplinary field that develops methods
  and software tools for understanding biological data.

Bioinformatics is as varied as biology itself, and ranges from data
analysis, to software development, computational or statistical
methodological development, more theoretical work, as well as any
combination of these.

## Omics data

So far, we have explored broad data science techniques in R. A
widespread and successful area of bioinformatics, and one that you, as
a biology or biomedical science student are likely to be confronted
with, is the analysis and interpretation of omics data.

```{r infoflow, results='markup', fig.margin=TRUE, fig.cap="Information flow in biological systems (Source [Wikipedia](https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology)).", fig.width=7, fig.height=7, echo=FALSE, purl=FALSE}
knitr::include_graphics("./figs/Centraldogma_nodetails.png")
```

It is useful to define these omics data along the flow of information
in biology (Figure \@ref(fig:infoflow)), and define the different
application domains. The technologies that focus on DNA, and the
genome in particular (either whole or parts thereof) are termed
**genomics**, and are currently based on sequencing, in particular
high throughput sequencing (HTS). The domain focusing on the study of
any DNA (or assiciated proteins) modification (such as for example
methylation) is termed **epigenetics**. The study of RNA, and more
specifically the quantitation of RNA levels in biological samples is
termed **transcriptomics**, as it assays the transcription of DNA into
RNA molecules. Without further specification, transcriptomics refers
to the quantitation of message RNA, although one could also focus on
non-coding RNAs such as micro RNAs. HTS is currently the technology of
choice for any transcriptomics study, while a decade ago, prior to the
development of RNA sequencing (called **RNA-Seq**), microarrays were
widely used. **Proteomics** focuses on the identification and
quantitation of proteins, and can also expand into the study of
protein interactions, post-translational modifications or sub-cellular
localisation of proteins. Further downstream of proteins, small
molecules or lipids can also be assayed under the umbrella terms of
**metabolomics** and **lipidomics**. The technology of choice for
protein, lipids or smaller metabolites is mass spectrometry.

In the next couple of sections, some important concepts related to
omics data and their analysis are repeated and emphasised.

### High throughput {-}

By it very nature, omics data is high throughput. The goal is to
measure all, or as many as possible molecules of an omics-domain as
possible: sequence the whole genome or all exomes; identify all
epigenetic histone modifications (defining the compactness of DNA and
hence it's accessibility by the transcription machinery); identify and
quantify as much as possible from the complete proteomics; etc. As a
result, omics data is both large in size and complex in nature, and
requires dedicated software and analysis methods to be processed,
analysed to infer biologically relevant patterns.

### Raw and processed data {-}

The omics data that are produced by the instruments are called raw
data, and their size (generally large), the types of file, and
structure will depend on the technology that is used. Raw data need to
be processed using dedicated software before obtaining data that can
be mapped to the biology that is measured. Below we illustrate two
such examples using Sanger sequencing and mass spectrometry.

In Sanger sequencing (Figure \@ref(fig:sangerseq)), DNA is labelled
using fluorophores, and different nucleotides are marked with
different colours. Upon acquisition, light signal is acquired and
recording of the different colours can be used to reconstruct the DNA
sequence.

```{r sangerseq, out.width = '70%', fig.cap="Processing Sanger sequencing data to a string. (Source [BiteSizeBio](https://bitesizebio.com/27985/sanger-sequencing-genome-won/)).", echo = FALSE}
knitr::include_graphics("./figs/sanger-sequencing.jpg")
```

In mass spectrometry, charged molecules are separated based on their
mass-to-charge (M/Z) ratio and their intensities recorded to produce a
spectrum. In proteomics, the molecules that are assayed are protein
fragments called peptides. Upon fragmentation of peptides, the
different between the M/Z peaks of the peptide fragment ions can be
used to reconstruct the peptide sequence (Figure \@ref(fig:pepseq)).

```{r pepseq, out.width = '100%', fig.cap="De novo peptide sequencing using mass spectrometry. (Source [Creative Proteomics](https://www.creative-proteomics.com/services/de-novo-peptides-proteins-sequencing-service.htm)).", echo = FALSE}
knitr::include_graphics("./figs/de-novo-pep-sequencing.jpg")
```


The size and computational cost of processing raw data often require
more serious hardware, including disk space, computer clusters with
100s or more of compute nodes and/or access to high amounts of memory
(RAM).

Processed data themselves often need to be further transformed to
account for a variety of noise that is inheritent to sample
collection, preparation and measurement acquisition. Data processing
and transformation will be explored in detail in subsequent course
such as *Omics data analysis*
([WSBIM2122](https://github.com/UCLouvain-CBIO/WSBIM2122)).


## Metadata and experimental design


The acquired data, even once processed, is still of very little use
when it comes to understanding biology. Before samples are collected
and data are generated, it is essential to carefully design a question
of interest (research hypothesis) and the experiement that will allow
to answer it. For example, if we want to understand the effect of a
particular drug on cancer cells, and more specifically understand the
effect on the transcription of all the expressed genes, on would need
to measure gene expression (using for example RNA-Seq) in cancer cells
in presence and absence of that drug. The table below describes a
simple experimental design where 3 conditions (control, drug at a
concentrations of 1 and 5) have been simultaneously processed and
measured by the same operator in 4 replicate.

```{r, echo = FALSE}
expd <- data.frame(sample = paste0("S", 1:12),
                   operator = "Kevin", date = '2019-03-02',
                   group = rep(c("CTRL", "DRUG", "DRUG"), each = 4),
                   concentration = factor(rep(c(0, 1, 5), each = 4)),
                   replicate = rep(1:4, 3),
                   stringsAsFactors = FALSE)
knitr::kable(expd)

```

We have seen a much more complex experimental desing, involving many
more samples with the `clinical1` data.

```{r, echo = FALSE, message = FALSE}
library("rWSBIM1207")
data(clinical1)
clinical1
```

When performing experiments, measurements should also be repeated
several times (typically at least three), to quantify technical
variability in the measured variables and, eventually, identify
changes that relate to the conditions of interest (i.e. differences in
genes expression in the presence or absence of the drug).

```{r, echo = FALSE, fig.cap = "Distribution of the expression of the genes A1CF, BRCA1 and TP53 under the control (no drug) and drug at concentrations 1 and 5."}
set.seed(1)
ge <- expd
ge$A1CF <- rnorm(12, 6, 2)
ge$BRCA1 <- c(abs(rnorm(4, 2, 1)), rnorm(4, 8, 2), rnorm(4, 13, 2))
ge$TP53 <-  c(rnorm(4, 10, 5), rnorm(4, 10, 3), rnorm(4, 10, 2))
ge <- gather(ge, key = gene, value = expression, A1CF, BRCA1, TP53)

ggplot(ge, aes(x = gene, y = expression, colour = concentration)) +
    geom_boxplot()
```

## Project management reminder

We have already seen some best practice related to data science
project management. These are applicable to bioinformatics projects
too of course[^bioindatascience]. William Noble (@Noble:2009) proposes
the following directory structure:

[^bioindatascience]: In this course, we consider bioinformatics as
    data science applied to biological or bio-medical data.

> Directory names are in large typeface, and filenames are in smaller
> typeface. Only a subset of the files are shown here. Note that the
> dates are formatted `<year>-<month>-<day>1` so that they can be
> sorted in chronological order. The source code `src/ms-analysis.c`
> is compiled to create `bin/ms-analysis` and is documented in
> `doc/ms-analysis.html`. The `README` files in the data directories
> specify who downloaded the data files from what URL on what
> date. The driver script `results/2009-01-15/runall` automatically
> generates the three subdirectories split1, split2, and split3,
> corresponding to three cross-validation splits. The
> `bin/parse-sqt.py` script is called by both of the `runall` driver
> scripts.


```{r bioinfoproj, fig.cap="Directory structure for a sample bioinformatics project.", out.width='100%', echo=FALSE}
knitr::include_graphics("./figs/noble-bioinfo-project.png")
```

The most important aspect of a well defined and well documented
project directory is to enable someone unfamiliar with the
project[^futureself] to

1. understand what the project is about, what data are available, what
   analyses were run, and what results were produced and, most
   importantly to

2. repeat the analysis over again - with new data, or changing some
   analysis parameters.

[^futureself]: That someone could be, and very likely will be your
    future self, a couple of months or years after the analyses were
    run.


In addition to the directory structure above, a **lab notebook**,
describing the different analyses that were done, why they were done,
and summarising the results are, is useful. The details of the
analysis are encoded in individual scripts and Rmarkdown or notebook
files, and don't need to be repeated again - here, it is important to
document the why something was done, rather then how something was
done. Such a general lab notebook could be a simple `README.md` file
or a reproducible Rmarkdown file, that could directly load some
results from the individual results files.


## The Bioconductor project {#sec:bioconductor}

The [Bioconductor](http://www.bioconductor.org) (@Gentleman:2004;@Huber:2015) ...

Package installation: reminder and `BiocManager::install`.


## Objects

Data in bioinformatics is often more complex than the basic data types
we have seen so far. Give a short introduction and example to some
relevant object.

## Documentation

Documenting ones tasks in a bioinformatics project is absolutely
essential. It is akin a lab notebook for wet lab.


## Exercises

More exercises, framed in the context of bioinformatics.
